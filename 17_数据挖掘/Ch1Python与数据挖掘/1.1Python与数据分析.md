# Python与数据分析
## 1.1 概述
**数据分析:数据构成分析,数据质量分析,统计学描述以及图表分析等**
> - 数据构成分析:通过观察数据信息以了解该数据的构成,数据类型分为数值型和类别型;

>  - 数据质量分析:观察数据集中是否出现异常值,缺失值,重复值等;

> - 统计学描述:通过计算了解数据信息的统计学意义的指标,如观察数据的均值,方差,标准差等;

> - 图表分析: 通过图表的方式将数据进行可视化处理.

**数据分析与数据挖掘**
|项目|数据分析|数据挖掘|
|---|---|---|
|定义|描述和探索性分析,评估现状和修正不足|技术性"采矿",发现未知模式和规律|
|侧重点|实际的业务知识|挖掘技术的落地,完成"采矿"|
|技能|统计学,数据库,可视化|数学与编程技术|
|结果|结合业务知识解读统计结果|模型或规则|
## 1.2 数据分析流程
**数据分析流程:明确目标,获取数据,清洗数据,特征工程,构建模型,模型评估**
> - **明确目标**:确认数据分析的目标,任务或对象

> - **获取数据**:Python爬虫爬取数据,相关数据集(内置数据集)
>> - 爬虫包括爬取,解析,存储三个主要步骤
>>**爬取:** 获取网页源代码,使用urllib,requets库等
>>**解析:** 从网页源代码中获取有用信息.一般有如下办法.
>>**存储:** 将提取到的数据保存到某处文件或数据库以进行后续处理和分析
>>>1. 使用正则表达式,使用re模块
>>>2. 网页具有规则结构可使用Beautiful Soup提取网页信息
>>>3. 如果是动态网页,采用Selenium

> - **清洗数据:** 数据分为类别型数据和数值型数据.类别型数据是指不可以直接测量的数据,如外貌,出生地等.数值型数据是可以直接测量的数据,如身高,体重,气温等.将数据的缺失值,异常值,重复值等"脏数据"通过第三方库进行清洗,确保结果的准确性.

>- **特征工程:**  通过NumPy,Scipy,Pandas 等对数据进行全面分析.了解***数据统计量***(如平均值,最值,中位数,方差等),***数据特征***(如数据的集中趋势,离散趋势,数据形状和变量间的关系等),***数据集中离散型变量的描述性统计值***(如不同离散值的个数,出现频次最高的离散值等).通过Scipy,Pandas,Sklearn等分析库对数据进行统一量纲等**标准化处理**,对数据进行高散化处理,采用哑变量,独热编码进行数据重编码,实施特征工程.

> - **构建模型:** 通过机器学习算法将数据集拆分为训练集和测试集.训练集用于模型的构建,测试集用于评估模型.
> > 1. 输入分类
> 如果数据带有标签,监督学习问题
> 如果数据没有标签,无监督学习问题
> > 2. 输出分类
> 如果输出是连续的数据,那么是回归问题
> 如果输出是离散的数据,那么是分类问题
> 如果输出是用输入数据划分的簇,那么是聚类问题

> - **模型评估:** 
> > 分类问题常见的评价标准有正确率,准确率,召回率,ROC曲线,AUC面积等
> 回归问题往往使用均方误差(MSE)等指标,也使用回归损失函数作为评价指标
## 1.3 数据分析库
(1)科学计算分析:Numpy
(2)数据分析与处理:Pandas,Scipy
(3)数据可视化:Matplotlib,Seaborn,Pandas,Scipy
(4)机器学习:Scikit-learn